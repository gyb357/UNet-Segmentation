# Main tasks
tasks:
  train: true
  test: false

# Model
model:
  channels: 3                  # Number of input channels
  num_classes: 1               # Number of output classes
  backbone: null               # Backbone architecture (e.g., resnet18, resnet34, resnet50, resnet101, resnet152)
  pretrained: null             # Pretrained model path
  freeze_backbone: false       # Whether to freeze backbone weights
  bias: false                  # Whether to use bias in convolutional layers
  normalize: null              # Normalization layer to use (default: nn.BatchNorm2d)
  dropout: 0.5                 # Dropout probability
  init_weights: false          # Whether to initialize weights

mask_dataset:
  # Leave 'label_path' or 'mask_path' empty if not used
  label_path: ""               # Path to the directory containing label files
  mask_path: ""                # Path where mask images will be saved
  mask_size: [320, 320]        # Size of the output mask (width, height)
  mask_extension: ".jpg"       # File extension for saved masks (e.g., .jpg, .png)
  mask_fill: 255               # Pixel value for the foreground (255 for white)

# Augmentation
augmentation:
  resize: [320, 320]           # Optional tuple for resizing (width, height)
  hflip: true                  # Whether to apply horizontal flip
  vflip: true                  # Whether to apply vertical flip
  rotate: 45.0                 # Maximum rotation angle (random angle between -rotate and +rotate)
  saturation: 0.2              # Maximum saturation adjustment factor
  brightness: 0.2              # Maximum brightness adjustment factor
  factor: 1.0                  # Global adjustment scale factor
  p: 0.5                       # Probability of applying each augmentation

# SegmentationDataset
segmentation_dataset:
  image_path: "dataset/image"  # Directory containing input images
  mask_path: "dataset/mask"    # Directory containing corresponding mask images
  extension: ".jpg"            # File extension for the images and masks (e.g., .jpg, .png)
  num_images: 0                # Maximum number of images to use (0 means use all)
  augmentation: true           # Whether to apply augmentations or not

# SegmentationDataLoader
segmentation_dataloader:
  batch_size: 8                # Batch size for data loading
  shuffle: true                # Whether to shuffle the data
  num_workers: 4               # Number of worker processes for data loading
  pin_memory: false            # Whether to pin memory for faster GPU transfer
  dataset_split:
    train: 0.8                 # Fraction of the data to be used for training
    valid: 0.1                   # Fraction of the data to be used for validation
    test: 0.1                  # Fraction of the data to be used for testing
  seed: 42                     # Random seed for reproducibility

# Trainer
trainer:
  lr: 0.0001                   # Learning rate for the optimizer
  loss: "BCEWithLogitsLoss"    # Loss function
  loss_coefficient:
    loss: 1.0                  # Coefficient for the loss function
    metric: 1.0                # Coefficient for the metric
  epochs: 100                  # Number of epochs to train the model
  accumulation_step: 1         # Number of steps to accumulate gradients
  checkpoint_step: 10          # Number of epochs to save model checkpoint
  show_time: 1                 # Number of steps to show sample images
  early_stopping_patience: 10  # Number of epochs to wait before early stopping
  mixed_precision: false       # Whether to use mixed precision training
  weight_decay: 0.0            # Weight decay for the optimizer
